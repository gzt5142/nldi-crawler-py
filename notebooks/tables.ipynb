{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.sql import text\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "connect_string=r\"postgresql+psycopg://nldi_schema_owner:changeMe@172.18.0.1:5432/nldi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=\"feature_xxx_tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = create_engine(connect_string, client_encoding=\"UTF-8\", echo=True, future=True)\n",
    "stmt=f\"\"\"\n",
    "    DROP TABLE IF EXISTS nldi_data.{tmp};\n",
    "    CREATE TABLE IF NOT EXISTS nldi_data.{tmp}\n",
    "        (LIKE nldi_data.feature INCLUDING INDEXES);\n",
    "\"\"\"\n",
    "with eng.connect() as connection:\n",
    "    r = connection.execute(text(stmt))\n",
    "    connection.commit()\n",
    "eng.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ijson import items, JSONError\n",
    "import logging\n",
    "fname = r\"../CrawlerData_10_dfw0go0s.geojson\"\n",
    "logging.basicConfig(level=logging.DEBUG, force=True)\n",
    "\n",
    "# def esc(s:str) ->str:\n",
    "#     if s is None:\n",
    "#         return \"\"\n",
    "#     return s.encode('ascii', errors='replace').decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import mapped_column, DeclarativeBase\n",
    "from sqlalchemy.orm import Mapped\n",
    "\n",
    "from sqlalchemy import String, Integer, Numeric, Text\n",
    "from geoalchemy2 import Geometry, Geography\n",
    "\n",
    "class NLDI_Base(DeclarativeBase):  # pylint: disable=invalid-name\n",
    "    \"\"\"Base class used to create reflected ORM objects.\"\"\"\n",
    "\n",
    "import sqlalchemy.types as types\n",
    "\n",
    "class StrippedString(types.TypeDecorator):\n",
    "    \"\"\"\n",
    "    Custom type to extend String.  We use this to forcefully remove any non-printing characters\n",
    "    from the input string. Some non-printables (including backspace and delete), if included\n",
    "    in the String, can mess with the SQL submitted by the connection engine. \n",
    "    \"\"\"\n",
    "    impl = types.String ## SQLAlchemy wants us to do it this way instead of subclassing String\n",
    "    cache_ok = True\n",
    "    def process_bind_param(self, s, dialect):\n",
    "        if s is None:\n",
    "            return \"\"\n",
    "        return s.encode('ascii', errors='replace').decode(\"utf-8\")\n",
    "\n",
    "\n",
    "class NLDI_Feature(NLDI_Base):\n",
    "    __tablename__ = \"feature_xxx_tmp\"\n",
    "    __table_args__ = {\"schema\": \"nldi_data\"}\n",
    "    comid = mapped_column(Integer)\n",
    "    identifier = mapped_column(StrippedString, primary_key=True)\n",
    "    crawler_source_id = mapped_column(Integer, primary_key=True)\n",
    "    name = mapped_column(StrippedString)\n",
    "    uri = mapped_column(StrippedString)\n",
    "    #location = mapped_column(StrippedString)\n",
    "    reachcode = mapped_column(StrippedString)\n",
    "    measure = mapped_column(Numeric(precision=38, scale=10))\n",
    "    shape = mapped_column(Geometry('POINT', srid=4269))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import from_geojson, to_wkt, to_wkb\n",
    "import json\n",
    "from geoalchemy2.shape import from_shape\n",
    "from geoalchemy2.elements import WKTElement, WKBElement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "eng = create_engine(connect_string, client_encoding=\"UTF-8\", echo=True, future=True)\n",
    "\n",
    "try:\n",
    "    i = 1\n",
    "    with open(fname, \"r\", encoding=\"UTF-8\") as read_fh:\n",
    "        with Session(eng) as session:\n",
    "            for itm in items(read_fh, \"features.item\", use_float=True):\n",
    "                i += 1\n",
    "                shp = from_geojson(json.dumps(itm['geometry']))\n",
    "                elmnt = WKTElement(to_wkt(shp), srid=4269)\n",
    "                #elmnt = to_wkt(shp)\n",
    "                logging.debug(\"%s\", itm['properties'])\n",
    "                try:\n",
    "                    m = float(itm['properties']['REACH_meas'])\n",
    "                except:\n",
    "                    m = 0.0\n",
    "                f = NLDI_Feature(\n",
    "                    identifier = itm['properties']['SBID'],\n",
    "                    crawler_source_id = 10,\n",
    "                    name = itm['properties']['Site Name'],\n",
    "                    uri = itm['properties']['SBURL'],\n",
    "                    #location = itm['properties']['Location'],\n",
    "                    reachcode = itm['properties']['REACHCODE'],\n",
    "                    measure = m, \n",
    "                    shape = elmnt\n",
    "                 ) \n",
    "                session.add(f)\n",
    "                session.commit()\n",
    "\n",
    "    logging.info(\" Processed %s features from %s\", i - 1, fname)\n",
    "except JSONError:\n",
    "    logging.warning(\" Parsing error; stopping after %s features read\", i - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfloat\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "float(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m itm\n",
      "\u001b[0;31mNameError\u001b[0m: name 'itm' is not defined"
     ]
    }
   ],
   "source": [
    "itm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import httpx\n",
    "\n",
    "url = 'http://winterolympicsmedals.com/medals.csv'\n",
    "response = urllib.request.urlopen(url)\n",
    "lines = [l.decode('utf-8') for l in response.readlines()]\n",
    "cr = csv.reader(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'crawler_source_id': '2', 'source_name': 'HUC12 Pour Points', 'source_suffix': 'huc12pp', 'source_uri': 'https://www.sciencebase.gov/catalogMaps/mapping/ows/5b4e25a6e4b06a6dd17e4879?service=WFS&version=1.0.0&request=GetFeature&srsName=EPSG:4326&typeName=sb:fpp&outputFormat=json', 'feature_id': 'HUC_12', 'feature_name': 'HUC_12', 'feature_uri': 'HUC_12', 'feature_reach': 'NULL', 'feature_measure': 'NULL', 'ingest_type': 'point', 'feature_type': 'hydrolocation'}\n",
      "{'crawler_source_id': '1', 'source_name': 'Water Quality Portal', 'source_suffix': 'WQP', 'source_uri': 'https://www.waterqualitydata.us/data/Station/search?mimeType=geojson&minactivities=1&counts=no', 'feature_id': 'MonitoringLocationIdentifier', 'feature_name': 'MonitoringLocationName', 'feature_uri': 'siteUrl', 'feature_reach': 'NULL', 'feature_measure': 'NULL', 'ingest_type': 'point', 'feature_type': 'varies'}\n",
      "{'crawler_source_id': '5', 'source_name': 'NWIS Surface Water Sites', 'source_suffix': 'nwissite', 'source_uri': 'https://www.sciencebase.gov/catalog/file/get/60c7b895d34e86b9389b2a6c?name=usgs_nldi_gages.geojson', 'feature_id': 'provider_id', 'feature_name': 'name', 'feature_uri': 'subjectOf', 'feature_reach': 'nhdpv2_REACHCODE', 'feature_measure': 'nhdpv2_REACH_measure', 'ingest_type': 'reach', 'feature_type': 'hydrolocation'}\n",
      "{'crawler_source_id': '6', 'source_name': 'Water Data Exchange 2.0 Sites', 'source_suffix': 'wade', 'source_uri': 'https://www.hydroshare.org/resource/5f665b7b82d74476930712f7e423a0d2/data/contents/wade.geojson', 'feature_id': 'feature_id', 'feature_name': 'feature_name', 'feature_uri': 'feature_uri', 'feature_reach': 'NULL', 'feature_measure': 'NULL', 'ingest_type': 'point', 'feature_type': 'varies'}\n",
      "{'crawler_source_id': '7', 'source_name': 'geoconnex.us reference gages', 'source_suffix': 'ref_gage', 'source_uri': 'https://www.hydroshare.org/resource/3295a17b4cc24d34bd6a5c5aaf753c50/data/contents/nldi_gages.geojson', 'feature_id': 'id', 'feature_name': 'name', 'feature_uri': 'subjectOf', 'feature_reach': 'nhdpv2_REACHCODE', 'feature_measure': 'nhdpv2_REACH_measure', 'ingest_type': 'reach', 'feature_type': 'hydrolocation'}\n",
      "{'crawler_source_id': '8', 'source_name': 'Streamgage catalog for CA SB19', 'source_suffix': 'ca_gages', 'source_uri': 'https://sb19.linked-data.internetofwater.dev/collections/ca_gages/items?f=json&limit=10000', 'feature_id': 'site_id', 'feature_name': 'sitename', 'feature_uri': 'uri', 'feature_reach': 'rchcd_medres', 'feature_measure': 'reach_measure', 'ingest_type': 'reach', 'feature_type': 'hydrolocation'}\n",
      "{'crawler_source_id': '9', 'source_name': 'USGS Geospatial Fabric V1.1 Points of Interest', 'source_suffix': 'gfv11_pois', 'source_uri': 'https://www.sciencebase.gov/catalogMaps/mapping/ows/609c8a63d34ea221ce3acfd3?service=WFS&version=1.0.0&request=GetFeature&srsName=EPSG:4326&typeName=sb::gfv11&outputFormat=json', 'feature_id': 'prvdr_d', 'feature_name': 'name', 'feature_uri': 'uri', 'feature_reach': 'n2_REACHC', 'feature_measure': 'n2_REACH_', 'ingest_type': 'reach', 'feature_type': 'hydrolocation'}\n",
      "{'crawler_source_id': '10', 'source_name': 'Vigil Network Data', 'source_suffix': 'vigil', 'source_uri': 'https://www.sciencebase.gov/catalog/file/get/60c7b895d34e86b9389b2a6c?name=vigil.geojson', 'feature_id': 'SBID', 'feature_name': 'Site Name', 'feature_uri': 'SBURL', 'feature_reach': 'REACHCODE', 'feature_measure': 'REACH_meas', 'ingest_type': 'reach', 'feature_type': 'hydrolocation'}\n",
      "{'crawler_source_id': '11', 'source_name': 'NWIS Groundwater Sites', 'source_suffix': 'nwisgw', 'source_uri': 'https://www.sciencebase.gov/catalog/file/get/60c7b895d34e86b9389b2a6c?name=nwis_wells.geojson', 'feature_id': 'provider_id', 'feature_name': 'name', 'feature_uri': 'subjectOf', 'feature_reach': 'NULL', 'feature_measure': 'NULL', 'ingest_type': 'point', 'feature_type': 'point'}\n",
      "{'crawler_source_id': '12', 'source_name': 'New Mexico Water Data Initative Sites', 'source_suffix': 'nmwdi-st', 'source_uri': 'https://locations.newmexicowaterdata.org/collections/Things/items?f=json&limit=100000', 'feature_id': 'id', 'feature_name': 'name', 'feature_uri': 'geoconnex', 'feature_reach': 'NULL', 'feature_measure': 'NULL', 'ingest_type': 'point', 'feature_type': 'point'}\n",
      "{'crawler_source_id': '13', 'source_name': 'geoconnex contribution demo sites', 'source_suffix': 'geoconnex-demo', 'source_uri': 'https://geoconnex-demo-pages.internetofwater.dev/collections/demo-gpkg/items?f=json&limit=10000', 'feature_id': 'fid', 'feature_name': 'GNIS_NAME', 'feature_uri': 'uri', 'feature_reach': 'NHDPv2ReachCode', 'feature_measure': 'NHDPv2Measure', 'ingest_type': 'reach', 'feature_type': 'hydrolocation'}\n"
     ]
    }
   ],
   "source": [
    "uri=r'https://raw.githubusercontent.com/internetofwater/nldi-db/gt-097-source-table-fixes/liquibase/changeLogs/nldi/nldi_data/update_crawler_source/crawler_source.tsv'\n",
    "# with httpx.stream(\"GET\", uri, timeout=60.0, follow_redirects=True) as r:\n",
    "#     for line in r.iter_lines():\n",
    "#         _reader = line.split(\"\\t\")\n",
    "#         print(_reader)\n",
    "\n",
    "tsv = httpx.get(uri)\n",
    "cr = csv.DictReader(tsv.text.splitlines(), delimiter=\"\\t\")\n",
    "for row in cr:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nldi_crawler import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrawlerSource(crawler_source_id=12, source_name='New Mexico Water Data Initative Sites', source_suffix='nmwdi-st', source_uri='https://locations.newmexicowaterdata.org/collections/Things/items?f=json&limit=100000', feature_id='id', feature_name='name', feature_uri='geoconnex', feature_reach='NULL', feature_measure='NULL', ingest_type='point', feature_type='point')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tsvsource=r'https://raw.githubusercontent.com/internetofwater/nldi-db/gt-097-source-table-fixes/liquibase/changeLogs/nldi/nldi_data/update_crawler_source/crawler_source.tsv'\n",
    "myrepo = src.CSVRepo(tsvsource)\n",
    "print(myrepo.get(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrawlerSource(crawler_source_id=12, source_name='New Mexico Water Data Initative Sites', source_suffix='nmwdi-st', source_uri='https://locations.newmexicowaterdata.org/collections/Things/items?f=json&limit=100000', feature_id='id', feature_name='name', feature_uri='geoconnex', feature_reach='', feature_measure='', ingest_type='point', feature_type='point')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = src.FakeSrcRepo()\n",
    "m.get(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedProtocol",
     "evalue": "Request URL is missing an 'http://' or 'https://' protocol.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedProtocol\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/nldi-crawler-py/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:60\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:  \u001b[39m# noqa: PIE-786\u001b[39;00m\n",
      "File \u001b[0;32m~/nldi-crawler-py/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:218\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 218\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    220\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/nldi-crawler-py/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:208\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mif\u001b[39;00m scheme \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m UnsupportedProtocol(\n\u001b[1;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRequest URL is missing an \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttp://\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://\u001b[39m\u001b[39m'\u001b[39m\u001b[39m protocol.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m     )\n\u001b[1;32m    211\u001b[0m \u001b[39mif\u001b[39;00m scheme \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mhttp\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhttps\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mws\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwss\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[0;31mUnsupportedProtocol\u001b[0m: Request URL is missing an 'http://' or 'https://' protocol.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mUnsupportedProtocol\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhttpx\u001b[39;00m\n\u001b[1;32m      2\u001b[0m uri\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/gt-src-repopattern/tests/sources.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m json_data \u001b[39m=\u001b[39m httpx\u001b[39m.\u001b[39;49mget(uri)\n",
      "File \u001b[0;32m~/nldi-crawler-py/.venv/lib/python3.10/site-packages/httpx/_api.py:189\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, headers, cookies, auth, proxies, follow_redirects, cert, verify, timeout, trust_env)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\n\u001b[1;32m    168\u001b[0m     url: URLTypes,\n\u001b[1;32m    169\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m     trust_env: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    180\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Response:\n\u001b[1;32m    181\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m    Sends a `GET` request.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39m    on this function, as `GET` requests should not include a request body.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\n\u001b[1;32m    190\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    191\u001b[0m         url,\n\u001b[1;32m    192\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    193\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    194\u001b[0m         cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[1;32m    195\u001b[0m         auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    196\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    197\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    198\u001b[0m         cert\u001b[39m=\u001b[39;49mcert,\n\u001b[1;32m    199\u001b[0m         verify\u001b[39m=\u001b[39;49mverify,\n\u001b[1;32m    200\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    201\u001b[0m         trust_env\u001b[39m=\u001b[39;49mtrust_env,\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m~/nldi-crawler-py/.venv/lib/python3.10/site-packages/httpx/_api.py:100\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, params, content, data, files, json, headers, cookies, auth, proxies, timeout, follow_redirects, verify, cert, trust_env)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mSends an HTTP request.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39mwith\u001b[39;00m Client(\n\u001b[1;32m     93\u001b[0m     cookies\u001b[39m=\u001b[39mcookies,\n\u001b[1;32m     94\u001b[0m     proxies\u001b[39m=\u001b[39mproxies,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m     trust_env\u001b[39m=\u001b[39mtrust_env,\n\u001b[1;32m     99\u001b[0m ) \u001b[39mas\u001b[39;00m client:\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mreturn\u001b[39;00m client\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    101\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    102\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    103\u001b[0m         content\u001b[39m=\u001b[39;49mcontent,\n\u001b[1;32m    104\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    105\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    106\u001b[0m         json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    107\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    108\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    109\u001b[0m         auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    110\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    111\u001b[0m     )\n",
      "File \u001b[0;32m~/nldi-crawler-py/.venv/lib/python3.10/site-packages/httpx/_client.py:821\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    806\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(message, \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    808\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_request(\n\u001b[1;32m    809\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[1;32m    810\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    819\u001b[0m     extensions\u001b[39m=\u001b[39mextensions,\n\u001b[1;32m    820\u001b[0m )\n\u001b[0;32m--> 821\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(request, auth\u001b[39m=\u001b[39;49mauth, follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects)\n",
      "File \u001b[0;32m~/nldi-crawler-py/.venv/lib/python3.10/site-packages/httpx/_client.py:908\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    900\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    902\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    903\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    904\u001b[0m )\n\u001b[1;32m    906\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 908\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    909\u001b[0m     request,\n\u001b[1;32m    910\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    911\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    912\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    913\u001b[0m )\n\u001b[1;32m    914\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/nldi-crawler-py/.venv/lib/python3.10/site-packages/httpx/_client.py:936\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    933\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    937\u001b[0m         request,\n\u001b[1;32m    938\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    939\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    940\u001b[0m     )\n\u001b[1;32m    941\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    942\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/nldi-crawler-py/.venv/lib/python3.10/site-packages/httpx/_client.py:973\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    971\u001b[0m     hook(request)\n\u001b[0;32m--> 973\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    974\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    975\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/nldi-crawler-py/.venv/lib/python3.10/site-packages/httpx/_client.py:1009\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1005\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1006\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1009\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1011\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1013\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m~/nldi-crawler-py/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:217\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(request\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m    205\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    206\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    207\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    216\u001b[0m )\n\u001b[0;32m--> 217\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    218\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool\u001b[39m.\u001b[39mhandle_request(req)\n\u001b[1;32m    220\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m     value \u001b[39m=\u001b[39m typ()\n\u001b[1;32m    152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(typ, value, traceback)\n\u001b[1;32m    154\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/nldi-crawler-py/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:77\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m     76\u001b[0m message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(exc)\n\u001b[0;32m---> 77\u001b[0m \u001b[39mraise\u001b[39;00m mapped_exc(message) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mUnsupportedProtocol\u001b[0m: Request URL is missing an 'http://' or 'https://' protocol."
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "uri=\"/gt-src-repopattern/tests/sources.json\"\n",
    "json_data = httpx.get(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data.status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import URL\n",
    "url = URL.create(\n",
    "        \"postgresql+psycopg2\",\n",
    "        username=\"nldi_schema_owner\",\n",
    "        password=\"changeMe\",\n",
    "        host=\"172.18.0.1\",\n",
    "        port=\"5432\",\n",
    "        database=\"nldi\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = src.SQLRepo(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrawlerSource(crawler_source_id=12, source_name='New Mexico Water Data Initative Sites', source_suffix='nmwdi-st', source_uri='https://locations.newmexicowaterdata.org/collections/Things/items?f=json&limit=100000', feature_id='id', feature_name='name', feature_uri='geoconnex', feature_reach=None, feature_measure=None, ingest_type='point', feature_type='point')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nldi-crawler-AikWVh81-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f23894094ed0d11a7fc7109fb6d8f7d7139f748cdac66a6988117f0bc49a024e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
