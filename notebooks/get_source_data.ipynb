{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Sources Table\n",
    "\n",
    "Schema/Table: nldi_data.crawler_source\n",
    "```text\n",
    ">COLUMN: {'name': 'crawler_source_id', 'type': INTEGER(), 'nullable': False, 'default': None, 'autoincrement': False, 'comment': None}\n",
    ">COLUMN: {'name': 'source_name', 'type': VARCHAR(length=500), 'nullable': False, 'default': None, 'autoincrement': False, 'comment': None}\n",
    ">COLUMN: {'name': 'source_suffix', 'type': VARCHAR(length=1000), 'nullable': False, 'default': None, 'autoincrement': False, 'comment': None}\n",
    ">COLUMN: {'name': 'source_uri', 'type': VARCHAR(length=256), 'nullable': False, 'default': None, 'autoincrement': False, 'comment': None}\n",
    ">COLUMN: {'name': 'feature_id', 'type': VARCHAR(length=500), 'nullable': False, 'default': None, 'autoincrement': False, 'comment': None}\n",
    ">COLUMN: {'name': 'feature_name', 'type': VARCHAR(length=500), 'nullable': False, 'default': None, 'autoincrement': False, 'comment': None}\n",
    ">COLUMN: {'name': 'feature_uri', 'type': VARCHAR(length=256), 'nullable': False, 'default': None, 'autoincrement': False, 'comment': None}\n",
    ">COLUMN: {'name': 'feature_reach', 'type': VARCHAR(length=500), 'nullable': True, 'default': None, 'autoincrement': False, 'comment': None}\n",
    ">COLUMN: {'name': 'feature_measure', 'type': VARCHAR(length=500), 'nullable': True, 'default': None, 'autoincrement': False, 'comment': None}\n",
    ">COLUMN: {'name': 'ingest_type', 'type': VARCHAR(length=5), 'nullable': True, 'default': None, 'autoincrement': False, 'comment': None}\n",
    ">COLUMN: {'name': 'feature_type', 'type': VARCHAR(length=100), 'nullable': True, 'default': None, 'autoincrement': False, 'comment': None}\n",
    "```\n",
    "\n",
    "This is the table of sources which govern where and how the crawler will look for data. Each row in that table is a potential source of data for the NLDI database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData, create_engine, inspect\n",
    "DB_URL=\"postgresql://nldi_schema_owner:changeMe@172.18.0.1:5432/nldi\" ## demo Database (CI is empty)\n",
    "CONN = create_engine(DB_URL, client_encoding=\"UTF-8\", echo=True)#, future=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = \"nldi_data\"\n",
    "TABLE = \"crawler_source\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = MetaData(bind=CONN, schema=SCHEMA)\n",
    "#m.reflect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import to a Pandas Dataframe\n",
    "\n",
    "Turns out that for simple tables (no relates or joins), it is very straightforward to import the 2D table into a Pandas dataframe.\n",
    "See <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql_table.html>.\n",
    "\n",
    "The complication here is that we don't want to use SQL Alchemy to manage the database connection.  The `read_sql_table` method is \n",
    "not yet implemented in SQL Alchemy 2.0.  But pandas \"knows\" enough about SQL that it can do a simple table select and populate\n",
    "a dataframe with the result.  The key is to give pandas the connection string rather than a connection engine object from SQL Alchemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connect directly to postgresql://nldi_schema_owner:changeMe@172.18.0.1:5432/nldi w/ pandas\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OptionEngine' object has no attribute 'execute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m#sources = pd.read_sql_table(table_name=TABLE, schema=SCHEMA, con=CONN)    ## NO !!!\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConnect directly to \u001b[39m\u001b[39m{\u001b[39;00mDB_URL\u001b[39m}\u001b[39;00m\u001b[39m w/ pandas\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m sources \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql_table(table_name\u001b[39m=\u001b[39;49mTABLE, schema\u001b[39m=\u001b[39;49mSCHEMA, con\u001b[39m=\u001b[39;49mDB_URL)    \u001b[39m## YES !!!\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#sources.set_index(\"crawler_source_id\", inplace=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nldi-crawler-AikWVh81-py3.9/lib/python3.9/site-packages/pandas/io/sql.py:286\u001b[0m, in \u001b[0;36mread_sql_table\u001b[0;34m(table_name, con, schema, index_col, coerce_float, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTable \u001b[39m\u001b[39m{\u001b[39;00mtable_name\u001b[39m}\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    284\u001b[0m \u001b[39m# error: Item \"SQLiteDatabase\" of \"Union[SQLDatabase, SQLiteDatabase]\"\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[39m# has no attribute \"read_table\"\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m table \u001b[39m=\u001b[39m pandas_sql\u001b[39m.\u001b[39;49mread_table(  \u001b[39m# type: ignore[union-attr]\u001b[39;49;00m\n\u001b[1;32m    287\u001b[0m     table_name,\n\u001b[1;32m    288\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    289\u001b[0m     coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m    290\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m    291\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m    292\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    295\u001b[0m \u001b[39mif\u001b[39;00m table \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m table\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nldi-crawler-AikWVh81-py3.9/lib/python3.9/site-packages/pandas/io/sql.py:1460\u001b[0m, in \u001b[0;36mSQLDatabase.read_table\u001b[0;34m(self, table_name, index_col, coerce_float, parse_dates, columns, schema, chunksize)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1418\u001b[0m \u001b[39mRead SQL database table into a DataFrame.\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1457\u001b[0m \n\u001b[1;32m   1458\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1459\u001b[0m table \u001b[39m=\u001b[39m SQLTable(table_name, \u001b[39mself\u001b[39m, index\u001b[39m=\u001b[39mindex_col, schema\u001b[39m=\u001b[39mschema)\n\u001b[0;32m-> 1460\u001b[0m \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m   1461\u001b[0m     coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m   1462\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m   1463\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   1464\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   1465\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nldi-crawler-AikWVh81-py3.9/lib/python3.9/site-packages/pandas/io/sql.py:1003\u001b[0m, in \u001b[0;36mSQLTable.read\u001b[0;34m(self, coerce_float, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1002\u001b[0m     sql_select \u001b[39m=\u001b[39m select(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtable)\n\u001b[0;32m-> 1003\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpd_sql\u001b[39m.\u001b[39;49mexecute(sql_select)\n\u001b[1;32m   1004\u001b[0m column_names \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mkeys()\n\u001b[1;32m   1006\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nldi-crawler-AikWVh81-py3.9/lib/python3.9/site-packages/pandas/io/sql.py:1405\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1403\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexecute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1404\u001b[0m     \u001b[39m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1405\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnectable\u001b[39m.\u001b[39;49mexecution_options()\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OptionEngine' object has no attribute 'execute'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#sources = pd.read_sql_table(table_name=TABLE, schema=SCHEMA, con=CONN)    ## NO !!!\n",
    "print(f\"Connect directly to {DB_URL} w/ pandas\")\n",
    "sources = pd.read_sql_table(table_name=TABLE, schema=SCHEMA, con=DB_URL)    ## YES !!!\n",
    "#sources.set_index(\"crawler_source_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sources' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sources\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sources' is not defined"
     ]
    }
   ],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nldi-crawler-AikWVh81-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Dec 14 2022, 13:52:45) \n[GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f23894094ed0d11a7fc7109fb6d8f7d7139f748cdac66a6988117f0bc49a024e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
